---
# Source: hlf-peer/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: customer1-peer0
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
---
# Source: hlf-peer/templates/secret--couchdb.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0--couchdb
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  COUCHDB_USER:  "Y291Y2hkYg=="
  COUCHDB_PASSWORD:  "Y291Y2hkYg=="
---
# Source: hlf-peer/templates/secret--peer-idcert.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0-idcert
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  cert.pem: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNUekNDQWZXZ0F3SUJBZ0lVWU5aLzVlSjlHankrSTd1WnVlWVgya0ZyYzljd0NnWUlLb1pJemowRUF3SXcKYWpFTE1Ba0dBMVVFQmhNQ1JWTXhFVEFQQmdOVkJBY1RDRUZzYVdOaGJuUmxNUkV3RHdZRFZRUUpFd2hCYkdsagpZVzUwWlRFWk1CY0dBMVVFQ2hNUVMzVnVaeUJHZFNCVGIyWjBkMkZ5WlRFTk1Bc0dBMVVFQ3hNRVZHVmphREVMCk1Ba0dBMVVFQXhNQ1kyRXdIaGNOTWpNeE1UQTNNRGN3T0RFeldoY05NalF4TVRBM01EY3hNREF3V2pBZU1RMHcKQ3dZRFZRUUxFd1J3WldWeU1RMHdDd1lEVlFRREV3UndaV1Z5TUZrd0V3WUhLb1pJemowQ0FRWUlLb1pJemowRApBUWNEUWdBRTFad0VPQ1RjckdGQmFSbGxkNGNmYlg0NVRyOXVFWlUxd3NuYlhxT0x5RUVYN2dCL2pSU2p0TitsCjBPKys1emNUejRKMEowdjBaeGhkcGVPZUJtUTd1YU9CeERDQndUQU9CZ05WSFE4QkFmOEVCQU1DQjRBd0RBWUQKVlIwVEFRSC9CQUl3QURBZEJnTlZIUTRFRmdRVWY2SFh3VXRPL1lvbXR2bk5LbWY4VU9MOUtiNHdLd1lEVlIwagpCQ1F3SW9BZ0hGZnlLUzVxMkdrWUpNcEZNV1ZvbFBDN0U5RG1tcmFvcnc1bit3UlpvVkl3VlFZSUtnTUVCUVlICkNBRUVTWHNpWVhSMGNuTWlPbnNpYUdZdVFXWm1hV3hwWVhScGIyNGlPaUlpTENKb1ppNUZibkp2Ykd4dFpXNTAKU1VRaU9pSndaV1Z5SWl3aWFHWXVWSGx3WlNJNkluQmxaWElpZlgwd0NnWUlLb1pJemowRUF3SURTQUF3UlFJaApBTHkrWlpJc2hHblJmTTQ0ZGR5aUV1eUNHaUF3MmRrTWc2RjE1M2FsWGZTaUFpQVJtd0QxdkhJU0gwOWlieSt6Clk2UnBxSkJod2EveXZBU0hqd1hkcVJTcm53PT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo="
---
# Source: hlf-peer/templates/secret--peer-idkey.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0-idkey
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  key.pem: "LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tCk1JR0hBZ0VBTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEJHMHdhd0lCQVFRZ1F1RU5CQnVQNE82bGJNaFMKRGZHeE5yM2RpK2Y2cTBDMzRPeC94UnUwUi9laFJBTkNBQVRWbkFRNEpOeXNZVUZwR1dWM2h4OXRmamxPdjI0UgpsVFhDeWR0ZW80dklRUmZ1QUgrTkZLTzAzNlhRNzc3bk54UFBnblFuUy9SbkdGMmw0NTRHWkR1NQotLS0tLUVORCBQUklWQVRFIEtFWS0tLS0tCg=="
---
# Source: hlf-peer/templates/secret--peer-ops-tls.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0-tls-ops
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  tls.crt: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURQakNDQXVTZ0F3SUJBZ0lVTmRaaC80OWpjSVpNeFBFeGdMa0RvaDJUQm5Rd0NnWUlLb1pJemowRUF3SXcKYlRFTE1Ba0dBMVVFQmhNQ1JWTXhFVEFQQmdOVkJBY1RDRUZzYVdOaGJuUmxNUkV3RHdZRFZRUUpFd2hCYkdsagpZVzUwWlRFWk1CY0dBMVVFQ2hNUVMzVnVaeUJHZFNCVGIyWjBkMkZ5WlRFTk1Bc0dBMVVFQ3hNRVZHVmphREVPCk1Bd0dBMVVFQXhNRmRHeHpZMkV3SGhjTk1qTXhNVEEzTURjd09ERXpXaGNOTWpReE1UQTNNRGN4TURBd1dqQWUKTVEwd0N3WURWUVFMRXdSd1pXVnlNUTB3Q3dZRFZRUURFd1J3WldWeU1Ga3dFd1lIS29aSXpqMENBUVlJS29aSQp6ajBEQVFjRFFnQUVLaStLakljTVZzOEdLMjNwdUhqZGJ5anZZQjlVVkpTK0FWMEx0RTNFcHZ6Skg3YXBKdDU5CmFuNWZsRjErdlhBT0VHeUVNeGM2UDdpU2F2QzJRdHExWnFPQ0FhOHdnZ0dyTUE0R0ExVWREd0VCL3dRRUF3SUQKcURBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUlLd1lCQlFVSEF3SXdEQVlEVlIwVEFRSC9CQUl3QURBZApCZ05WSFE0RUZnUVU1a3ZuZGpEOUFSTWF1QTVPcE1zekNxdzY5dFV3S3dZRFZSMGpCQ1F3SW9BZ0dRL2hxNHhICmViZ0lpR0I1U1NwUUNJNWNDR0dabFdCbjg2ZzloSW9hNHBjd2djZ0dBMVVkRVFTQndEQ0J2WUlKYkc5allXeG8KYjNOMGdnOWpkWE4wYjIxbGNqRXRjR1ZsY2pDQ0hXTjFjM1J2YldWeU1TMXdaV1Z5TUM1amRYTjBiMjFsY2pFdApibVYwZ2pOd1pXVnlNQzVqZFhOMGIyMWxjakV0Ym1WMExtOXlaekp3Y205NGVTNXdhRzlsYm1sNFlteHZZMnRqCmFHRnBiaTVqYjIyQ00zQmxaWEl3TG1OMWMzUnZiV1Z5TVMxdVpYUXViM0puTW5CeWIzaDVMbkJvYjJWdWFYaGkKYkc5amEyTm9ZV2x1TG1OdmJZY0Vmd0FBQVljRUNrWXdDb2NFQ2tZd0U0Y0VDa1l3TWpCVkJnZ3FBd1FGQmdjSQpBUVJKZXlKaGRIUnljeUk2ZXlKb1ppNUJabVpwYkdsaGRHbHZiaUk2SWlJc0ltaG1Ma1Z1Y205c2JHMWxiblJKClJDSTZJbkJsWlhJaUxDSm9aaTVVZVhCbElqb2ljR1ZsY2lKOWZUQUtCZ2dxaGtqT1BRUURBZ05JQURCRkFpRUEKOUJ5NEFvVjBxdis2cThaS2E2S1ZyajZRRzR1UXdZSjRleDNSZXJxb1JrTUNJRTFrZTlnN2hMT2J1L1RHbVFqRgpXZ212SWl6bHRGNWhBVWp3Mk44Mmxhd00KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo="
  tls.key: "LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tCk1JR0hBZ0VBTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEJHMHdhd0lCQVFRZ0Ywd3BSSWVjUGpRTDBFVSsKak41WnhhRmxCSDVzWldCSFdSN2g0UmVzenNtaFJBTkNBQVFxTDRxTWh3eFd6d1lyYmVtNGVOMXZLTzlnSDFSVQpsTDRCWFF1MFRjU20vTWtmdHFrbTNuMXFmbCtVWFg2OWNBNFFiSVF6RnpvL3VKSnE4TFpDMnJWbQotLS0tLUVORCBQUklWQVRFIEtFWS0tLS0tCg=="
---
# Source: hlf-peer/templates/secret--peer-tls.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0-tls
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  tls.crt: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURQakNDQXVTZ0F3SUJBZ0lVRXl4ZDlXUWtDMTMrekM1WjRaOFZkSDV6VWRVd0NnWUlLb1pJemowRUF3SXcKYlRFTE1Ba0dBMVVFQmhNQ1JWTXhFVEFQQmdOVkJBY1RDRUZzYVdOaGJuUmxNUkV3RHdZRFZRUUpFd2hCYkdsagpZVzUwWlRFWk1CY0dBMVVFQ2hNUVMzVnVaeUJHZFNCVGIyWjBkMkZ5WlRFTk1Bc0dBMVVFQ3hNRVZHVmphREVPCk1Bd0dBMVVFQXhNRmRHeHpZMkV3SGhjTk1qTXhNVEEzTURjd09ERXpXaGNOTWpReE1UQTNNRGN4TURBd1dqQWUKTVEwd0N3WURWUVFMRXdSd1pXVnlNUTB3Q3dZRFZRUURFd1J3WldWeU1Ga3dFd1lIS29aSXpqMENBUVlJS29aSQp6ajBEQVFjRFFnQUVna2VIcUcxVnhmYU5YVmRHZmZ0UnRDaFdVVExrMlIxejN5UFJINDdFcENYcTlmZEE2aWFiCkxJVjV5eHN3c05wL2VhdytCL2s0MlpMMzk4cG1SZWU2cmFPQ0FhOHdnZ0dyTUE0R0ExVWREd0VCL3dRRUF3SUQKcURBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUlLd1lCQlFVSEF3SXdEQVlEVlIwVEFRSC9CQUl3QURBZApCZ05WSFE0RUZnUVVVdit1WTU4WjFHSjJld0hpQnNnWGV3djBMcnN3S3dZRFZSMGpCQ1F3SW9BZ0dRL2hxNHhICmViZ0lpR0I1U1NwUUNJNWNDR0dabFdCbjg2ZzloSW9hNHBjd2djZ0dBMVVkRVFTQndEQ0J2WUlKYkc5allXeG8KYjNOMGdnOWpkWE4wYjIxbGNqRXRjR1ZsY2pDQ0hXTjFjM1J2YldWeU1TMXdaV1Z5TUM1amRYTjBiMjFsY2pFdApibVYwZ2pOd1pXVnlNQzVqZFhOMGIyMWxjakV0Ym1WMExtOXlaekp3Y205NGVTNXdhRzlsYm1sNFlteHZZMnRqCmFHRnBiaTVqYjIyQ00zQmxaWEl3TG1OMWMzUnZiV1Z5TVMxdVpYUXViM0puTW5CeWIzaDVMbkJvYjJWdWFYaGkKYkc5amEyTm9ZV2x1TG1OdmJZY0Vmd0FBQVljRUNrWXdDb2NFQ2tZd0U0Y0VDa1l3TWpCVkJnZ3FBd1FGQmdjSQpBUVJKZXlKaGRIUnljeUk2ZXlKb1ppNUJabVpwYkdsaGRHbHZiaUk2SWlJc0ltaG1Ma1Z1Y205c2JHMWxiblJKClJDSTZJbkJsWlhJaUxDSm9aaTVVZVhCbElqb2ljR1ZsY2lKOWZUQUtCZ2dxaGtqT1BRUURBZ05JQURCRkFpRUEKaG13dkhnTklhSzRUUS94eW9xUGFSOVhEZElqNTRYWXNTeTFjZ0JyeVpkQUNJRDJmN0JDVXY1U3I0MTYrdUNYRgpqTThWc1ltaWNISTNsRlY5TWVvRkdXZjYKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo="
  tls.key: "LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tCk1JR0hBZ0VBTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEJHMHdhd0lCQVFRZ3FsUldiaTBaSUZVRFJJbDkKQTd3T20zTXFzTXppRDcyTEZiZkwxMHd3MjcyaFJBTkNBQVNDUjRlb2JWWEY5bzFkVjBaOSsxRzBLRlpSTXVUWgpIWFBmSTlFZmpzU2tKZXIxOTBEcUpwc3NoWG5MR3pDdzJuOTVyRDRIK1RqWmt2ZjN5bVpGNTdxdAotLS0tLUVORCBQUklWQVRFIEtFWS0tLS0tCg=="
---
# Source: hlf-peer/templates/secret--peerorg-cacert.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0-cacert
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  cacert.pem: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNQekNDQWVhZ0F3SUJBZ0lSQUllWkRnSXpPQVJLMWtWYjlwbG9PUjR3Q2dZSUtvWkl6ajBFQXdJd2FqRUwKTUFrR0ExVUVCaE1DUlZNeEVUQVBCZ05WQkFjVENFRnNhV05oYm5SbE1SRXdEd1lEVlFRSkV3aEJiR2xqWVc1MApaVEVaTUJjR0ExVUVDaE1RUzNWdVp5QkdkU0JUYjJaMGQyRnlaVEVOTUFzR0ExVUVDeE1FVkdWamFERUxNQWtHCkExVUVBeE1DWTJFd0hoY05Nak14TVRBM01EY3dPREV6V2hjTk16TXhNVEE0TURjd09ERXpXakJxTVFzd0NRWUQKVlFRR0V3SkZVekVSTUE4R0ExVUVCeE1JUVd4cFkyRnVkR1V4RVRBUEJnTlZCQWtUQ0VGc2FXTmhiblJsTVJrdwpGd1lEVlFRS0V4QkxkVzVuSUVaMUlGTnZablIzWVhKbE1RMHdDd1lEVlFRTEV3UlVaV05vTVFzd0NRWURWUVFECkV3SmpZVEJaTUJNR0J5cUdTTTQ5QWdFR0NDcUdTTTQ5QXdFSEEwSUFCUFdMcW9xZmNPcTNtbE4xZWx5Y2w3eHQKdjAxVldkS1dxUS9wbnByT2UrdTY3SUk4RDRLNVNUZE00bTVkMVM5bW93VjRadEp1QjdEeCt0ZHQ3c0prTVcyagpiVEJyTUE0R0ExVWREd0VCL3dRRUF3SUJwakFkQmdOVkhTVUVGakFVQmdnckJnRUZCUWNEQWdZSUt3WUJCUVVICkF3RXdEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXBCZ05WSFE0RUlnUWdIRmZ5S1M1cTJHa1lKTXBGTVdWb2xQQzcKRTlEbW1yYW9ydzVuK3dSWm9WSXdDZ1lJS29aSXpqMEVBd0lEUndBd1JBSWdQSjZsZmhPWHJjYURHZ3JseEc0egpDNTNScys1ZDMwNGFaRllCYmZOV2FlY0NJSEFmNUY0VXhaYnVTRUdYeHl6bDlIQlh5MVlTRFRWTnFzcml2OWppClk3U3kKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo="
---
# Source: hlf-peer/templates/secret--peerorg-tlsrootcert.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0-tlsrootcert
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  cacert.pem: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNSVENDQWV5Z0F3SUJBZ0lSQU9JL00yMUUzYmQvUk1FOW1DMVJnNWt3Q2dZSUtvWkl6ajBFQXdJd2JURUwKTUFrR0ExVUVCaE1DUlZNeEVUQVBCZ05WQkFjVENFRnNhV05oYm5SbE1SRXdEd1lEVlFRSkV3aEJiR2xqWVc1MApaVEVaTUJjR0ExVUVDaE1RUzNWdVp5QkdkU0JUYjJaMGQyRnlaVEVOTUFzR0ExVUVDeE1FVkdWamFERU9NQXdHCkExVUVBeE1GZEd4elkyRXdIaGNOTWpNeE1UQTNNRGN3T0RFeldoY05Nek14TVRBNE1EY3dPREV6V2pCdE1Rc3cKQ1FZRFZRUUdFd0pGVXpFUk1BOEdBMVVFQnhNSVFXeHBZMkZ1ZEdVeEVUQVBCZ05WQkFrVENFRnNhV05oYm5SbApNUmt3RndZRFZRUUtFeEJMZFc1bklFWjFJRk52Wm5SM1lYSmxNUTB3Q3dZRFZRUUxFd1JVWldOb01RNHdEQVlEClZRUURFd1YwYkhOallUQlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDlBd0VIQTBJQUJCZEVQSkMrUU1YZWwzdEEKU0tFR0RKWWFUdys5ajJCWW1FcmVXVGwzOGxnSWRaWW1vWEhDbi8ybVNWdllxQlFTUklkTmtIbktFRzdpNy9aego2UHprcEl1amJUQnJNQTRHQTFVZER3RUIvd1FFQXdJQnBqQWRCZ05WSFNVRUZqQVVCZ2dyQmdFRkJRY0RBZ1lJCkt3WUJCUVVIQXdFd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBcEJnTlZIUTRFSWdRZ0dRL2hxNHhIZWJnSWlHQjUKU1NwUUNJNWNDR0dabFdCbjg2ZzloSW9hNHBjd0NnWUlLb1pJemowRUF3SURSd0F3UkFJZ0JRUmtjNWxDNkxHSgpvVGcrOHRIdGxrQ0xxUWkwRXdnYUNRMHFuZEVqcXFrQ0lDQ2xhUmxYVVhLU2xWVXVsaWtZdVEzLytQT3poNk1ZCnFnS3g3NUFrZ3M2OAotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
---
# Source: hlf-peer/templates/secret--tlsclientrootcert.yaml
apiVersion: v1
kind: Secret
metadata:
  name: customer1-peer0--tlsclientrootcerts
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
type: Opaque
data:
  cert.pem: "LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUNSVENDQWV5Z0F3SUJBZ0lSQU9JL00yMUUzYmQvUk1FOW1DMVJnNWt3Q2dZSUtvWkl6ajBFQXdJd2JURUwKTUFrR0ExVUVCaE1DUlZNeEVUQVBCZ05WQkFjVENFRnNhV05oYm5SbE1SRXdEd1lEVlFRSkV3aEJiR2xqWVc1MApaVEVaTUJjR0ExVUVDaE1RUzNWdVp5QkdkU0JUYjJaMGQyRnlaVEVOTUFzR0ExVUVDeE1FVkdWamFERU9NQXdHCkExVUVBeE1GZEd4elkyRXdIaGNOTWpNeE1UQTNNRGN3T0RFeldoY05Nek14TVRBNE1EY3dPREV6V2pCdE1Rc3cKQ1FZRFZRUUdFd0pGVXpFUk1BOEdBMVVFQnhNSVFXeHBZMkZ1ZEdVeEVUQVBCZ05WQkFrVENFRnNhV05oYm5SbApNUmt3RndZRFZRUUtFeEJMZFc1bklFWjFJRk52Wm5SM1lYSmxNUTB3Q3dZRFZRUUxFd1JVWldOb01RNHdEQVlEClZRUURFd1YwYkhOallUQlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDlBd0VIQTBJQUJCZEVQSkMrUU1YZWwzdEEKU0tFR0RKWWFUdys5ajJCWW1FcmVXVGwzOGxnSWRaWW1vWEhDbi8ybVNWdllxQlFTUklkTmtIbktFRzdpNy9aego2UHprcEl1amJUQnJNQTRHQTFVZER3RUIvd1FFQXdJQnBqQWRCZ05WSFNVRUZqQVVCZ2dyQmdFRkJRY0RBZ1lJCkt3WUJCUVVIQXdFd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBcEJnTlZIUTRFSWdRZ0dRL2hxNHhIZWJnSWlHQjUKU1NwUUNJNWNDR0dabFdCbjg2ZzloSW9hNHBjd0NnWUlLb1pJemowRUF3SURSd0F3UkFJZ0JRUmtjNWxDNkxHSgpvVGcrOHRIdGxrQ0xxUWkwRXdnYUNRMHFuZEVqcXFrQ0lDQ2xhUmxYVVhLU2xWVXVsaWtZdVEzLytQT3poNk1ZCnFnS3g3NUFrZ3M2OAotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg=="
---
# Source: hlf-peer/templates/config-ou.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: customer1-peer0-nodeou
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
data:
  config.yaml: |
    NodeOUs:
      Enable: true
      ClientOUIdentifier:
        Certificate: cacerts/cacert.pem
        OrganizationalUnitIdentifier: client
      PeerOUIdentifier:
        Certificate: cacerts/cacert.pem
        OrganizationalUnitIdentifier: peer
      AdminOUIdentifier:
        Certificate: cacerts/cacert.pem
        OrganizationalUnitIdentifier: admin
      OrdererOUIdentifier:
        Certificate: cacerts/cacert.pem
        OrganizationalUnitIdentifier: orderer
---
# Source: hlf-peer/templates/configmap--peer--core.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: customer1-peer0--peer--core
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
data:
  core.yaml: |
    # Copyright IBM Corp. All Rights Reserved.
    #
    # SPDX-License-Identifier: Apache-2.0
    #

    ###############################################################################
    #
    #    Peer section
    #
    ###############################################################################
    peer:

      # The peer id provides a name for this peer instance and is used when
      # naming docker resources.
      id: jdoe

      # The networkId allows for logical separation of networks and is used when
      # naming docker resources.
      networkId: dev

      # The Address at local network interface this Peer will listen on.
      # By default, it will listen on all network interfaces
      listenAddress: 0.0.0.0:7051

      # The endpoint this peer uses to listen for inbound chaincode connections.
      # If this is commented-out, the listen address is selected to be
      # the peer's address (see below) with port 7052
      # chaincodeListenAddress: 0.0.0.0:7052

      # The endpoint the chaincode for this peer uses to connect to the peer.
      # If this is not specified, the chaincodeListenAddress address is selected.
      # And if chaincodeListenAddress is not specified, address is selected from
      # peer address (see below). If specified peer address is invalid then it
      # will fallback to the auto detected IP (local IP) regardless of the peer
      # addressAutoDetect value.
      # chaincodeAddress: 0.0.0.0:7052

      # When used as peer config, this represents the endpoint to other peers
      # in the same organization. For peers in other organization, see
      # gossip.externalEndpoint for more info.
      # When used as CLI config, this means the peer's endpoint to interact with
      address: 0.0.0.0:7051

      # Whether the Peer should programmatically determine its address
      # This case is useful for docker containers.
      # When set to true, will override peer address.
      addressAutoDetect: false

      # Keepalive settings for peer server and clients
      keepalive:
        # Interval is the duration after which if the server does not see
        # any activity from the client it pings the client to see if it's alive
        interval: 7200s
        # Timeout is the duration the server waits for a response
        # from the client after sending a ping before closing the connection
        timeout: 20s
        # MinInterval is the minimum permitted time between client pings.
        # If clients send pings more frequently, the peer server will
        # disconnect them
        minInterval: 60s
        # Client keepalive settings for communicating with other peer nodes
        client:
          # Interval is the time between pings to peer nodes.  This must
          # greater than or equal to the minInterval specified by peer
          # nodes
          interval: 60s
          # Timeout is the duration the client waits for a response from
          # peer nodes before closing the connection
          timeout: 20s
        # DeliveryClient keepalive settings for communication with ordering
        # nodes.
        deliveryClient:
          # Interval is the time between pings to ordering nodes.  This must
          # greater than or equal to the minInterval specified by ordering
          # nodes.
          interval: 60s
          # Timeout is the duration the client waits for a response from
          # ordering nodes before closing the connection
          timeout: 20s


      # Gossip related configuration
      gossip:
        # Bootstrap set to initialize gossip with.
        # This is a list of other peers that this peer reaches out to at startup.
        # Important: The endpoints here have to be endpoints of peers in the same
        # organization, because the peer would refuse connecting to these endpoints
        # unless they are in the same organization as the peer.
        bootstrap: 127.0.0.1:7051

        # NOTE: orgLeader and useLeaderElection parameters are mutual exclusive.
        # Setting both to true would result in the termination of the peer
        # since this is undefined state. If the peers are configured with
        # useLeaderElection=false, make sure there is at least 1 peer in the
        # organization that its orgLeader is set to true.

        # Defines whenever peer will initialize dynamic algorithm for
        # "leader" selection, where leader is the peer to establish
        # connection with ordering service and use delivery protocol
        # to pull ledger blocks from ordering service.
        useLeaderElection: false
        # Statically defines peer to be an organization "leader",
        # where this means that current peer will maintain connection
        # with ordering service and disseminate block across peers in
        # its own organization. Multiple peers or all peers in an organization
        # may be configured as org leaders, so that they all pull
        # blocks directly from ordering service.
        orgLeader: true

        # Interval for membershipTracker polling
        membershipTrackerInterval: 5s

        # Overrides the endpoint that the peer publishes to peers
        # in its organization. For peers in foreign organizations
        # see 'externalEndpoint'
        endpoint:
        # Maximum count of blocks stored in memory
        maxBlockCountToStore: 10
        # Max time between consecutive message pushes(unit: millisecond)
        maxPropagationBurstLatency: 10ms
        # Max number of messages stored until a push is triggered to remote peers
        maxPropagationBurstSize: 10
        # Number of times a message is pushed to remote peers
        propagateIterations: 1
        # Number of peers selected to push messages to
        propagatePeerNum: 3
        # Determines frequency of pull phases(unit: second)
        # Must be greater than digestWaitTime + responseWaitTime
        pullInterval: 4s
        # Number of peers to pull from
        pullPeerNum: 3
        # Determines frequency of pulling state info messages from peers(unit: second)
        requestStateInfoInterval: 4s
        # Determines frequency of pushing state info messages to peers(unit: second)
        publishStateInfoInterval: 4s
        # Maximum time a stateInfo message is kept until expired
        stateInfoRetentionInterval:
        # Time from startup certificates are included in Alive messages(unit: second)
        publishCertPeriod: 10s
        # Should we skip verifying block messages or not (currently not in use)
        skipBlockVerification: false
        # Dial timeout(unit: second)
        dialTimeout: 3s
        # Connection timeout(unit: second)
        connTimeout: 2s
        # Buffer size of received messages
        recvBuffSize: 20
        # Buffer size of sending messages
        sendBuffSize: 200
        # Time to wait before pull engine processes incoming digests (unit: second)
        # Should be slightly smaller than requestWaitTime
        digestWaitTime: 1s
        # Time to wait before pull engine removes incoming nonce (unit: milliseconds)
        # Should be slightly bigger than digestWaitTime
        requestWaitTime: 1500ms
        # Time to wait before pull engine ends pull (unit: second)
        responseWaitTime: 2s
        # Alive check interval(unit: second)
        aliveTimeInterval: 5s
        # Alive expiration timeout(unit: second)
        aliveExpirationTimeout: 25s
        # Reconnect interval(unit: second)
        reconnectInterval: 25s
        # Max number of attempts to connect to a peer
        maxConnectionAttempts: 120
        # Message expiration factor for alive messages
        msgExpirationFactor: 20
        # This is an endpoint that is published to peers outside of the organization.
        # If this isn't set, the peer will not be known to other organizations.
        externalEndpoint:
        # Leader election service configuration
        election:
          # Longest time peer waits for stable membership during leader election startup (unit: second)
          startupGracePeriod: 15s
          # Interval gossip membership samples to check its stability (unit: second)
          membershipSampleInterval: 1s
          # Time passes since last declaration message before peer decides to perform leader election (unit: second)
          leaderAliveThreshold: 10s
          # Time between peer sends propose message and declares itself as a leader (sends declaration message) (unit: second)
          leaderElectionDuration: 5s

        pvtData:
          # pullRetryThreshold determines the maximum duration of time private data corresponding for a given block
          # would be attempted to be pulled from peers until the block would be committed without the private data
          pullRetryThreshold: 60s
          # As private data enters the transient store, it is associated with the peer's ledger's height at that time.
          # transientstoreMaxBlockRetention defines the maximum difference between the current ledger's height upon commit,
          # and the private data residing inside the transient store that is guaranteed not to be purged.
          # Private data is purged from the transient store when blocks with sequences that are multiples
          # of transientstoreMaxBlockRetention are committed.
          transientstoreMaxBlockRetention: 1000
          # pushAckTimeout is the maximum time to wait for an acknowledgement from each peer
          # at private data push at endorsement time.
          pushAckTimeout: 3s
          # Block to live pulling margin, used as a buffer
          # to prevent peer from trying to pull private data
          # from peers that is soon to be purged in next N blocks.
          # This helps a newly joined peer catch up to current
          # blockchain height quicker.
          btlPullMargin: 10
          # the process of reconciliation is done in an endless loop, while in each iteration reconciler tries to
          # pull from the other peers the most recent missing blocks with a maximum batch size limitation.
          # reconcileBatchSize determines the maximum batch size of missing private data that will be reconciled in a
          # single iteration.
          reconcileBatchSize: 10
          # reconcileSleepInterval determines the time reconciler sleeps from end of an iteration until the beginning
          # of the next reconciliation iteration.
          reconcileSleepInterval: 1m
          # reconciliationEnabled is a flag that indicates whether private data reconciliation is enable or not.
          reconciliationEnabled: true
          # skipPullingInvalidTransactionsDuringCommit is a flag that indicates whether pulling of invalid
          # transaction's private data from other peers need to be skipped during the commit time and pulled
          # only through reconciler.
          skipPullingInvalidTransactionsDuringCommit: false
          # implicitCollectionDisseminationPolicy specifies the dissemination  policy for the peer's own implicit collection.
          # When a peer endorses a proposal that writes to its own implicit collection, below values override the default values
          # for disseminating private data.
          # Note that it is applicable to all channels the peer has joined. The implication is that requiredPeerCount has to
          # be smaller than the number of peers in a channel that has the lowest numbers of peers from the organization.
          implicitCollectionDisseminationPolicy:
            # requiredPeerCount defines the minimum number of eligible peers to which the peer must successfully
            # disseminate private data for its own implicit collection during endorsement. Default value is 0.
            requiredPeerCount: 0
            # maxPeerCount defines the maximum number of eligible peers to which the peer will attempt to
            # disseminate private data for its own implicit collection during endorsement. Default value is 1.
            maxPeerCount: 1

        # Gossip state transfer related configuration
        state:
          # indicates whenever state transfer is enabled or not
          # default value is true, i.e. state transfer is active
          # and takes care to sync up missing blocks allowing
          # lagging peer to catch up to speed with rest network
          enabled: false
          # checkInterval interval to check whether peer is lagging behind enough to
          # request blocks via state transfer from another peer.
          checkInterval: 10s
          # responseTimeout amount of time to wait for state transfer response from
          # other peers
          responseTimeout: 3s
          # batchSize the number of blocks to request via state transfer from another peer
          batchSize: 10
          # blockBufferSize reflects the size of the re-ordering buffer
          # which captures blocks and takes care to deliver them in order
          # down to the ledger layer. The actual buffer size is bounded between
          # 0 and 2*blockBufferSize, each channel maintains its own buffer
          blockBufferSize: 20
          # maxRetries maximum number of re-tries to ask
          # for single state transfer request
          maxRetries: 3

      # TLS Settings
      tls:
        # Require server-side TLS
        enabled:  false
        # Require client certificates / mutual TLS.
        # Note that clients that are not configured to use a certificate will
        # fail to connect to the peer.
        clientAuthRequired: false
        # X.509 certificate used for TLS server
        cert:
          file: tls/server.crt
        # Private key used for TLS server (and client if clientAuthEnabled
        # is set to true
        key:
          file: tls/server.key
        # Trusted root certificate chain for tls.cert
        rootcert:
          file: tls/ca.crt
        # Set of root certificate authorities used to verify client certificates
        clientRootCAs:
          files:
            - tls/ca.crt
        # Private key used for TLS when making client connections.  If
        # not set, peer.tls.key.file will be used instead
        clientKey:
          file:
        # X.509 certificate used for TLS when making client connections.
        # If not set, peer.tls.cert.file will be used instead
        clientCert:
          file:

      # Authentication contains configuration parameters related to authenticating
      # client messages
      authentication:
        # the acceptable difference between the current server time and the
        # client's time as specified in a client request message
        timewindow: 15m

      # Path on the file system where peer will store data (eg ledger). This
      # location must be access control protected to prevent unintended
      # modification that might corrupt the peer operations.
      fileSystemPath: /var/hyperledger/production

      # BCCSP (Blockchain crypto provider): Select which crypto implementation or
      # library to use
      BCCSP:
        Default: SW
        # Settings for the SW crypto provider (i.e. when DEFAULT: SW)
        SW:
          # TODO: The default Hash and Security level needs refactoring to be
          # fully configurable. Changing these defaults requires coordination
          # SHA2 is hardcoded in several places, not only BCCSP
          Hash: SHA2
          Security: 256
          # Location of Key Store
          FileKeyStore:
            # If "", defaults to 'mspConfigPath'/keystore
            KeyStore:
        # Settings for the PKCS#11 crypto provider (i.e. when DEFAULT: PKCS11)
        PKCS11:
          # Location of the PKCS11 module library
          Library:
          # Token Label
          Label:
          # User PIN
          Pin:
          Hash:
          Security:

      # Path on the file system where peer will find MSP local configurations
      mspConfigPath: msp

      # Identifier of the local MSP
      # ----!!!!IMPORTANT!!!-!!!IMPORTANT!!!-!!!IMPORTANT!!!!----
      # Deployers need to change the value of the localMspId string.
      # In particular, the name of the local MSP ID of a peer needs
      # to match the name of one of the MSPs in each of the channel
      # that this peer is a member of. Otherwise this peer's messages
      # will not be identified as valid by other nodes.
      localMspId: SampleOrg

      # CLI common client config options
      client:
        # connection timeout
        connTimeout: 3s

      # Delivery service related config
      deliveryclient:
        # It sets the total time the delivery service may spend in reconnection
        # attempts until its retry logic gives up and returns an error
        reconnectTotalTimeThreshold: 3600s

        # It sets the delivery service <-> ordering service node connection timeout
        connTimeout: 3s

        # It sets the delivery service maximal delay between consecutive retries
        reConnectBackoffThreshold: 3600s

        # A list of orderer endpoint addresses which should be overridden
        # when found in channel configurations.
        addressOverrides:
        #  - from:
        #    to:
        #    caCertsFile:
        #  - from:
        #    to:
        #    caCertsFile:

      # Type for the local MSP - by default it's of type bccsp
      localMspType: bccsp

      # Used with Go profiling tools only in none production environment. In
      # production, it should be disabled (eg enabled: false)
      profile:
        enabled:     false
        listenAddress: 0.0.0.0:6060

      # Handlers defines custom handlers that can filter and mutate
      # objects passing within the peer, such as:
      #   Auth filter - reject or forward proposals from clients
      #   Decorators  - append or mutate the chaincode input passed to the chaincode
      #   Endorsers   - Custom signing over proposal response payload and its mutation
      # Valid handler definition contains:
      #   - A name which is a factory method name defined in
      #     core/handlers/library/library.go for statically compiled handlers
      #   - library path to shared object binary for pluggable filters
      # Auth filters and decorators are chained and executed in the order that
      # they are defined. For example:
      # authFilters:
      #   -
      #     name: FilterOne
      #     library: /opt/lib/filter.so
      #   -
      #     name: FilterTwo
      # decorators:
      #   -
      #     name: DecoratorOne
      #   -
      #     name: DecoratorTwo
      #     library: /opt/lib/decorator.so
      # Endorsers are configured as a map that its keys are the endorsement system chaincodes that are being overridden.
      # Below is an example that overrides the default ESCC and uses an endorsement plugin that has the same functionality
      # as the default ESCC.
      # If the 'library' property is missing, the name is used as the constructor method in the builtin library similar
      # to auth filters and decorators.
      # endorsers:
      #   escc:
      #     name: DefaultESCC
      #     library: /etc/hyperledger/fabric/plugin/escc.so
      handlers:
        authFilters:
          -
            name: DefaultAuth
          -
            name: ExpirationCheck    # This filter checks identity x509 certificate expiration
        decorators:
          -
            name: DefaultDecorator
        endorsers:
          escc:
            name: DefaultEndorsement
            library:
        validators:
          vscc:
            name: DefaultValidation
            library:

      #    library: /etc/hyperledger/fabric/plugin/escc.so
      # Number of goroutines that will execute transaction validation in parallel.
      # By default, the peer chooses the number of CPUs on the machine. Set this
      # variable to override that choice.
      # NOTE: overriding this value might negatively influence the performance of
      # the peer so please change this value only if you know what you're doing
      validatorPoolSize:

      # The discovery service is used by clients to query information about peers,
      # such as - which peers have joined a certain channel, what is the latest
      # channel config, and most importantly - given a chaincode and a channel,
      # what possible sets of peers satisfy the endorsement policy.
      discovery:
        enabled: true
        # Whether the authentication cache is enabled or not.
        authCacheEnabled: true
        # The maximum size of the cache, after which a purge takes place
        authCacheMaxSize: 1000
        # The proportion (0 to 1) of entries that remain in the cache after the cache is purged due to overpopulation
        authCachePurgeRetentionRatio: 0.75
        # Whether to allow non-admins to perform non channel scoped queries.
        # When this is false, it means that only peer admins can perform non channel scoped queries.
        orgMembersAllowedAccess: false

      # Limits is used to configure some internal resource limits.
      limits:
        # Concurrency limits the number of concurrently running requests to a service on each peer.
        # Currently this option is only applied to endorser service and deliver service.
        # When the property is missing or the value is 0, the concurrency limit is disabled for the service.
        concurrency:
          # endorserService limits concurrent requests to endorser service that handles chaincode deployment, query and invocation,
          # including both user chaincodes and system chaincodes.
          endorserService: 2500
          # deliverService limits concurrent event listeners registered to deliver service for blocks and transaction events.
          deliverService: 2500

    ###############################################################################
    #
    #    VM section
    #
    ###############################################################################
    vm:

      # Endpoint of the vm management system.  For docker can be one of the following in general
      # unix:///var/run/docker.sock
      # http://localhost:2375
      # https://localhost:2376
      endpoint: ""

      # settings for docker vms
      docker:
        tls:
          enabled: false
          ca:
            file: docker/ca.crt
          cert:
            file: docker/tls.crt
          key:
            file: docker/tls.key

        # Enables/disables the standard out/err from chaincode containers for
        # debugging purposes
        attachStdout: false

        # Parameters on creating docker container.
        # Container may be efficiently created using ipam & dns-server for cluster
        # NetworkMode - sets the networking mode for the container. Supported
        # standard values are: `host`(default),`bridge`,`ipvlan`,`none`.
        # Dns - a list of DNS servers for the container to use.
        # Note:  `Privileged` `Binds` `Links` and `PortBindings` properties of
        # Docker Host Config are not supported and will not be used if set.
        # LogConfig - sets the logging driver (Type) and related options
        # (Config) for Docker. For more info,
        # https://docs.docker.com/engine/admin/logging/overview/
        # Note: Set LogConfig using Environment Variables is not supported.
        hostConfig:
          NetworkMode: host
          Dns:
          # - 192.168.0.1
          LogConfig:
            Type: json-file
            Config:
              max-size: "50m"
              max-file: "5"
          Memory: 2147483648

    ###############################################################################
    #
    #    Chaincode section
    #
    ###############################################################################
    chaincode:

      # The id is used by the Chaincode stub to register the executing Chaincode
      # ID with the Peer and is generally supplied through ENV variables
      # the `path` form of ID is provided when installing the chaincode.
      # The `name` is used for all other requests and can be any string.
      id:
        path:
        name:

      # Generic builder environment, suitable for most chaincode types
      builder: $(DOCKER_NS)/fabric-ccenv:$(TWO_DIGIT_VERSION)

      pull: false

      golang:
        # golang will never need more than baseos
        runtime: $(DOCKER_NS)/fabric-baseos:$(TWO_DIGIT_VERSION)

        # whether or not golang chaincode should be linked dynamically
        dynamicLink: false

      java:
        # This is an image based on java:openjdk-8 with addition compiler
        # tools added for java shim layer packaging.
        # This image is packed with shim layer libraries that are necessary
        # for Java chaincode runtime.
        runtime: $(DOCKER_NS)/fabric-javaenv:$(TWO_DIGIT_VERSION)

      node:
        # This is an image based on node:$(NODE_VER)-alpine
        runtime: $(DOCKER_NS)/fabric-nodeenv:$(TWO_DIGIT_VERSION)

      # List of directories to treat as external builders and launchers for
      # chaincode. The external builder detection processing will iterate over the
      # builders in the order specified below.
      externalBuilders:
        - name: ccaas_builder
          path: /opt/hyperledger/ccaas_builder
          propagateEnvironment:
          - CHAINCODE_AS_A_SERVICE_BUILDER_CONFIG
      # The maximum duration to wait for the chaincode build and install process
      # to complete.
      installTimeout: 8m0s

      # Timeout duration for starting up a container and waiting for Register
      # to come through.
      startuptimeout: 5m0s

      # Timeout duration for Invoke and Init calls to prevent runaway.
      # This timeout is used by all chaincodes in all the channels, including
      # system chaincodes.
      # Note that during Invoke, if the image is not available (e.g. being
      # cleaned up when in development environment), the peer will automatically
      # build the image, which might take more time. In production environment,
      # the chaincode image is unlikely to be deleted, so the timeout could be
      # reduced accordingly.
      executetimeout: 30s

      # There are 2 modes: "dev" and "net".
      # In dev mode, user runs the chaincode after starting peer from
      # command line on local machine.
      # In net mode, peer will run chaincode in a docker container.
      mode: net

      # keepalive in seconds. In situations where the communication goes through a
      # proxy that does not support keep-alive, this parameter will maintain connection
      # between peer and chaincode.
      # A value <= 0 turns keepalive off
      keepalive: 0

      # enabled system chaincodes
      system:
        _lifecycle: enable
        cscc: enable
        lscc: enable
        escc: enable
        vscc: enable
        qscc: enable

      # Logging section for the chaincode container
      logging:
        # Default level for all loggers within the chaincode container
        level:  info
        # Override default level for the 'shim' logger
        shim:   warning
        # Format for the chaincode container logs
        format: '%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -> %{level:.4s} %{id:03x}%{color:reset} %{message}'

    ###############################################################################
    #
    #    Ledger section - ledger configuration encompasses both the blockchain
    #    and the state
    #
    ###############################################################################
    ledger:

      blockchain:
      snapshots:
        rootDir: /var/hyperledger/production/snapshots

      state:
        # stateDatabase - options are "goleveldb", "CouchDB"
        # goleveldb - default state database stored in goleveldb.
        # CouchDB - store state database in CouchDB
        stateDatabase: goleveldb
        # Limit on the number of records to return per query
        totalQueryLimit: 100000
        couchDBConfig:
          # It is recommended to run CouchDB on the same server as the peer, and
          # not map the CouchDB container port to a server port in docker-compose.
          # Otherwise proper security must be provided on the connection between
          # CouchDB client (on the peer) and server.
          couchDBAddress: 127.0.0.1:5984
          # This username must have read and write authority on CouchDB
          username:
          # The password is recommended to pass as an environment variable
          # during start up (eg CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD).
          # If it is stored here, the file must be access control protected
          # to prevent unintended users from discovering the password.
          password:
          # Number of retries for CouchDB errors
          maxRetries: 3
          # Number of retries for CouchDB errors during peer startup.
          # The delay between retries doubles for each attempt.
          # Default of 10 retries results in 11 attempts over 2 minutes.
          maxRetriesOnStartup: 10
          # CouchDB request timeout (unit: duration, e.g. 20s)
          requestTimeout: 35s
          # Limit on the number of records per each CouchDB query
          # Note that chaincode queries are only bound by totalQueryLimit.
          # Internally the chaincode may execute multiple CouchDB queries,
          # each of size internalQueryLimit.
          internalQueryLimit: 1000
          # Limit on the number of records per CouchDB bulk update batch
          maxBatchUpdateSize: 1000
          # Warm indexes after every N blocks.
          # This option warms any indexes that have been
          # deployed to CouchDB after every N blocks.
          # A value of 1 will warm indexes after every block commit,
          # to ensure fast selector queries.
          # Increasing the value may improve write efficiency of peer and CouchDB,
          # but may degrade query response time.
          warmIndexesAfterNBlocks: 1
          # Create the _global_changes system database
          # This is optional.  Creating the global changes database will require
          # additional system resources to track changes and maintain the database
          createGlobalChangesDB: false
          # CacheSize denotes the maximum mega bytes (MB) to be allocated for the in-memory state
          # cache. Note that CacheSize needs to be a multiple of 32 MB. If it is not a multiple
          # of 32 MB, the peer would round the size to the next multiple of 32 MB.
          # To disable the cache, 0 MB needs to be assigned to the cacheSize.
          cacheSize: 64

      history:
        # enableHistoryDatabase - options are true or false
        # Indicates if the history of key updates should be stored.
        # All history 'index' will be stored in goleveldb, regardless if using
        # CouchDB or alternate database for the state.
        enableHistoryDatabase: true

      pvtdataStore:
        # the maximum db batch size for converting
        # the ineligible missing data entries to eligible missing data entries
        collElgProcMaxDbBatchSize: 5000
        # the minimum duration (in milliseconds) between writing
        # two consecutive db batches for converting the ineligible missing data entries to eligible missing data entries
        collElgProcDbBatchesInterval: 1000

    ###############################################################################
    #
    #    Operations section
    #
    ###############################################################################
    operations:
      # host and port for the operations server
      listenAddress: 127.0.0.1:9443

      # TLS configuration for the operations endpoint
      tls:
        # TLS enabled
        enabled: false

        # path to PEM encoded server certificate for the operations server
        cert:
          file:

        # path to PEM encoded server key for the operations server
        key:
          file:

        # most operations service endpoints require client authentication when TLS
        # is enabled. clientAuthRequired requires client certificate authentication
        # at the TLS layer to access all resources.
        clientAuthRequired: false

        # paths to PEM encoded ca certificates to trust for client authentication
        clientRootCAs:
          files: []

    ###############################################################################
    #
    #    Metrics section
    #
    ###############################################################################
    metrics:
      # metrics provider is one of statsd, prometheus, or disabled
      provider: disabled

      # statsd configuration
      statsd:
        # network type: tcp or udp
        network: udp

        # statsd server address
        address: 127.0.0.1:8125

        # the interval at which locally cached counters and gauges are pushed
        # to statsd; timings are pushed immediately
        writeInterval: 10s

        # prefix is prepended to all emitted statsd metrics
        prefix:
---
# Source: hlf-peer/templates/configmap--peer.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: customer1-peer0--peer
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
data:
  CORE_PEER_ID: customer1-peer0
  CORE_PEER_NETWORKID: customer1-peer0-nid
  CORE_PEER_ADDRESSAUTODETECT: "true"
  # If we have an ingress, we set hostname to it
  CORE_PEER_ADDRESS: peer0.customer1-net.org2proxy.phoenixblockchain.com:443
  CORE_PEER_GOSSIP_EXTERNALENDPOINT: "peer0.customer1-net.org2proxy.phoenixblockchain.com:443"
  CORE_PEER_GOSSIP_BOOTSTRAP: ""
  CORE_PEER_GOSSIP_ENDPOINT: "peer0.customer1-net.org2proxy.phoenixblockchain.com:443"
  CORE_PEER_LISTENADDRESS: 0.0.0.0:7051
  CORE_PEER_CHAINCODELISTENADDRESS: 0.0.0.0:7052
  CORE_PEER_EVENTS_ADDRESS: 0.0.0.0:7053
  CORE_PEER_COMMITTER_ENABLED: "true"
  CORE_PEER_PROFILE_ENABLED: "true"
  CORE_PEER_DISCOVERY_PERIOD: 60s
  CORE_PEER_DISCOVERY_TOUCHPERIOD: 60s
  CORE_PEER_LOCALMSPID: "customer1MSP"
  CORE_PEER_MSPCONFIGPATH: /var/hyperledger/msp
  ##############
  # Operations #
  ##############
  CORE_OPERATIONS_TLS_ENABLED: "false"
  CORE_OPERATIONS_TLS_KEY_FILE: "/var/hyperledger/tls/operations/pair/tls.key"
  CORE_OPERATIONS_TLS_CERT_FILE: "/var/hyperledger/tls/operations/pair/tls.crt"
  CORE_OPERATIONS_TLS_CLIENTAUTHREQUIRED: "false"
  CORE_OPERATIONS_LISTENADDRESS: "0.0.0.0:9443"
  CORE_OPERATIONS_TLS_CLIENTROOTCAS_FILES: "/var/hyperledger/tls/server/cert/cacert.pem"
  ##############
  # Events #
  ##############
  CORE_PEER_EVENTS_ADDRESS: "0.0.0.0:7053"
  ##############
  # Metrics #
  ##############
  CORE_METRICS_PROVIDER: "prometheus"
  # Logging #
  ###########
  #CORE_LOGGING_LEVEL: "info"
  FABRIC_LOGGING_SPEC: "info"
  CORE_LOGGING_PEER: "info"
  CORE_LOGGING_CAUTHDSL: "info"
  CORE_LOGGING_GOSSIP: "info"
  CORE_LOGGING_LEDGER: "info"
  CORE_LOGGING_MSP: "info"
  CORE_LOGGING_POLICIES: "info"
  CORE_LOGGING_GRPC: "info"
  ##########
  # Gossip #
  ##########

  CORE_PEER_GOSSIP_ORGLEADER: "false"
  CORE_PEER_GOSSIP_USELEADERELECTION: "true"
  ##########
  # TLS    #
  ##########
  CORE_PEER_TLS_ENABLED: "true"
  CORE_PEER_TLS_CERT_FILE: "/var/hyperledger/tls/server/pair/tls.crt"
  CORE_PEER_TLS_KEY_FILE: "/var/hyperledger/tls/server/pair/tls.key"
  CORE_PEER_TLS_ROOTCERT_FILE: "/var/hyperledger/tls/server/cert/cacert.pem"
  CORE_PEER_TLS_CLIENTAUTHREQUIRED: "false"
  # This is fixed prior to starting the peer
  CORE_PEER_TLS_CLIENTROOTCAS_FILES: "/var/hyperledger/tls/client/cert/*"
  CORE_PEER_TLS_CLIENTCERT_FILE: "/var/hyperledger/tls/client/pair/tls.crt"
  CORE_PEER_TLS_CLIENTKEY_FILE: "/var/hyperledger/tls/client/pair/tls.key"
  CORE_LEDGER_STATE_STATEDATABASE: "CouchDB"
  # Containers in the same pod share the host
  CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS: localhost:5984
  PEER_CFG_PATH: /var/hyperledger/config
  FABRIC_CFG_PATH: /var/hyperledger/fabric_cfg
  ADMIN_MSP_PATH: /var/hyperledger/admin_msp
  ORD_TLS_PATH: /var/hyperledger/tls/ord/cert
---
# Source: hlf-peer/templates/pvc-couchdb.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: customer1-peer0--couchdb
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "5Gi"
  storageClassName: "customer1-azure-storageclass"
---
# Source: hlf-peer/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: customer1-peer0
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "2Gi"
  storageClassName: "customer1-azure-storageclass"
---
# Source: hlf-peer/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: customer1-peer0
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
rules:
  - apiGroups:
      - ""
      - extensions
    resources:
      - pods/status
      - pods/log
    verbs:
      - create
      - get
      - list
      - update
      - watch
      - patch
  - apiGroups:
      - ""
      - extensions
    resources:
      - pods
    verbs:
      - get
      - list
      - watch
      - create
      - delete
---
# Source: hlf-peer/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: customer1-peer0-customer1-net
  namespace: customer1-net
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: customer1-peer0
subjects:
  - kind: ServiceAccount
    name: customer1-peer0
    namespace: customer1-net
---
# Source: hlf-peer/templates/service-fs.yaml
apiVersion: v1
kind: Service
metadata:
  name: customer1-peer0-fs
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
  selector:
    app: hlf-peer
    release: customer1-peer0
---
# Source: hlf-peer/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customer1-peer0
  labels:
    app: hlf-peer
    heritage: "Helm"
    release: "customer1-peer0"
    chart: hlf-peer-1.3.0
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hlf-peer
      release: customer1-peer0
  # Ensure we allow our pod to be unavailable, so we can upgrade
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        checksum/configmap--peer: 428f63d851bf48bfa24808098f6b6b2a6519a393a8d831b66d65a2ee6b65
        checksum/configmap--peer--core: 6be6fb57294af85160f28b44cf978d5b9bdeab48f10cd2f809b153fc63cc
        checksum/config-ou: da577bb8def6204e84af402d50d8461fbf87e8d6e5673014aa1088f36686
        checksum/secret--couchdb: 0a7c57aa58632d3313c3d5e8ec100d05c419bb1b87fb497e560675615b7d
        checksum/secret--peer-idcert: 5dc2a596163493d5e3514f010ed36a985e0dc5aab365eb8572fee0cd0bb7
        checksum/secret--peer-idkey: 58cca8fdaeaa6903221dc57c686d9c8f426d4c6b18c153f45fe32f08fa6b
        checksum/secret--peer-ops-tls: 394d09574ec27210618e7b176f48361fe6fde4980e3f0e3ee3003f1f601e
        checksum/secret--peer-tls: 6dfe5b420d8092e14c75c065462157a996ad5eb442b6bdd5263d4709f02e
        checksum/secret--peerorg-cacert: cb9c90308b4a0445addba96ec7a1e82d683f018ad19252e13b9e3a14c074
        checksum/secret--peerorg-intcacert: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852
        checksum/secret--peerorg-tlsintcacert: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852
        checksum/secret--peerorg-tlsrootcert: 3ffa931646f5aeb1442653cff593652a013e2245b097a3c905b7d0b0c6c4
        checksum/secret--tlsclientrootcert: e71fcda19f8d1235c0b5f518b08bf398f5b0c55b1815248db8523090c0fe
        app: hlf-peer
        heritage: "Helm"
        release: "customer1-peer0"
        chart: hlf-peer-1.3.0
    spec:
      serviceAccountName: customer1-peer0
      hostAliases:
          null
      volumes:
        - name: couchdb
          persistentVolumeClaim:
            claimName: customer1-peer0--couchdb
        - name: data
          persistentVolumeClaim:
            claimName: customer1-peer0
        - name: peerconfig
          configMap:
            name: customer1-peer0--peer--core
        - name: id-cert
          secret:
            secretName: customer1-peer0-idcert
        - name: id-key
          secret:
            secretName: customer1-peer0-idkey
        - name: cacert
          secret:
            secretName: customer1-peer0-cacert
        - name: tls-clientrootcert
          secret:
            secretName: customer1-peer0--tlsclientrootcerts
        - name: nodeou
          configMap:
            name: 'customer1-peer0-nodeou'
            items:
              - key: 'config.yaml'
                path: 'config.yaml'
        - name: tls
          secret:
            secretName: "customer1-peer0-tls"
        - name: tls-ops
          secret:
            secretName: "customer1-peer0-tls-ops"
        - name: tls-rootcert
          secret:
            secretName: "customer1-peer0-tlsrootcert"
        - name: tls-client
          secret:
            secretName: "customer1-peer0-tls"
      containers:

        - name: peer
          image: "hyperledger/fabric-peer:2.5.3"
          imagePullPolicy: Always
          ports:
            - name: request
              containerPort: 7051
              protocol: TCP
            - name: event
              containerPort: 7053
              protocol: TCP
            - name: operations
              containerPort: 9443
              protocol: TCP
          livenessProbe:
            successThreshold: 1
            failureThreshold: 3
            timeoutSeconds: 5
            httpGet:
              port: 9443
              path: /healthz
            initialDelaySeconds: 5
            periodSeconds: 5
          readinessProbe:
            httpGet:
              port: 9443
              path: /healthz
            initialDelaySeconds: 5
            failureThreshold: 3
            successThreshold: 1
            periodSeconds: 5
          command:
            - /bin/sh
            - -c
            - |
              echo "\033[0;31m peer node initialization \033[0m"
              # To avoid having separate secrets for CouchDB and HLF
              export CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=$COUCHDB_USER
              export CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=$COUCHDB_PASSWORD

              while [ ! -d ${CORE_PEER_MSPCONFIGPATH}/signcerts ];
              do
                echo "\033[0;31m ${CORE_PEER_MSPCONFIGPATH}/signcerts directory must exist \033[0m"
                sleep 60
              done
              if [ ! -d ${FABRIC_CFG_PATH} ]
              then
                mkdir -p ${FABRIC_CFG_PATH}
                cp -r /etc/hyperledger/fabric/core.yaml ${FABRIC_CFG_PATH}
                ls ${FABRIC_CFG_PATH}
              fi


              echo ">\033[0;35m peer node start \033[0m"
              peer node start
          #              sleep 6000000

          envFrom:
            - secretRef:
                name: customer1-peer0--couchdb
            - configMapRef:
                name: customer1-peer0--peer
          volumeMounts:
            - name: peerconfig
              mountPath: /var/hyperledger/fabric_cfg
            - mountPath: /var/hyperledger
              name: data
            - mountPath: /var/hyperledger/msp/signcerts
              name: id-cert
            - mountPath: /var/hyperledger/msp/keystore
              name: id-key
            - mountPath: /var/hyperledger/msp/cacerts
              name: cacert
            - mountPath: /var/hyperledger/admin_msp/cacerts

              name: cacert
            - mountPath: /var/hyperledger/msp/tlscacerts
              name: tls-rootcert
            - mountPath: /var/hyperledger/msp/config.yaml
              name: nodeou
              subPath: config.yaml
            - mountPath: /var/hyperledger/tls/client/pair
              name: tls-client
            - mountPath: /var/hyperledger/tls/client/cert
              name: tls-clientrootcert
            - mountPath: /var/hyperledger/tls/server/pair
              name: tls
            - mountPath: /var/hyperledger/tls/operations/pair
              name: tls-ops
            - mountPath: /var/hyperledger/tls/server/cert
              name: tls-rootcert
          resources:
            limits:
              cpu: "1"
              memory: 512Mi
            requests:
              cpu: 10m
              memory: 128Mi
        - name: couchdb
          image: "couchdb:3.1.1"
          imagePullPolicy: Always
          ports:
            - name: couchdb
              containerPort: 5984
              protocol: TCP
          volumeMounts:
            - mountPath: /opt/couchdb/data
              name: couchdb
          envFrom:
            - secretRef:
                name: customer1-peer0--couchdb
          livenessProbe:
            tcpSocket:
              port: 5984
            initialDelaySeconds: 60
            timeoutSeconds: 5
            failureThreshold: 6
          readinessProbe:
            tcpSocket:
              port: 5984
            initialDelaySeconds: 5
            timeoutSeconds: 3
            periodSeconds: 5
          resources:
            limits:
              cpu: "1"
              memory: 512Mi
            requests:
              cpu: 10m
              memory: 10m
---
# Source: hlf-peer/templates/istio-gateway.yaml
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: customer1-peer0-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 443
        name: tcp
        protocol: TLS
      tls:
        mode: PASSTHROUGH
      hosts:
          - peer0.customer1-net.org2proxy.phoenixblockchain.com
---
# Source: hlf-peer/templates/virtualservice.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: customer1-peer0-virtualservice
spec:
  hosts:
    - peer0.customer1-net.org2proxy.phoenixblockchain.com
  gateways:
    - customer1-peer0-gateway
  tls:
    - match:
        - port: 443
          sniHosts:
              - peer0.customer1-net.org2proxy.phoenixblockchain.com
      route:
        - destination:
            host: customer1-peer0
            port:
              number: 7051

